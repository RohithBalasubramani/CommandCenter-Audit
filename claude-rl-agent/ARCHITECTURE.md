# Claude Behavioral Replication Agent - Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER INTERACTION WITH CLAUDE CODE                     â”‚
â”‚   "What's the difference between transformer 1 and transformer 2?"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  CLAUDE'S WORKFLOW DESIGN & EXECUTION                    â”‚
â”‚                                                                          â”‚
â”‚  Planning:   "Need to compare two DB entities"                          â”‚
â”‚              "Design: Schema â†’ Search â†’ Query â†’ Compare"                â”‚
â”‚                                                                          â”‚
â”‚  Execution:  Read("schema.py") â†’ "Understand structure"                 â”‚
â”‚              Grep("transformer") â†’ "Find references"                     â”‚
â”‚              Bash("psql trf_1") â†’ "Query transformer 1"                  â”‚
â”‚              Bash("psql trf_2") â†’ "Query transformer 2"                  â”‚
â”‚                                                                          â”‚
â”‚  Synthesis:  Compare â†’ Analyze â†’ Generate answer                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ CAPTURE
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              REASONING SIGNAL EXTRACTOR (reasoning_extractor.py)         â”‚
â”‚                                                                          â”‚
â”‚  Extracts:                                                               â”‚
â”‚    âœ“ Tool sequence: [Read, Grep, Bash, Bash]                           â”‚
â”‚    âœ“ Reasoning chain: ["First...", "Then...", "Next..."]               â”‚
â”‚    âœ“ Constraint detection: What limitations Claude identified           â”‚
â”‚    âœ“ Pruning decisions: What approaches Claude rejected                 â”‚
â”‚    âœ“ Self-corrections: How Claude adapted mid-workflow                  â”‚
â”‚    âœ“ Exploration depth: Minimal | Moderate | Thorough | Exhaustive     â”‚
â”‚                                                                          â”‚
â”‚  Output: ClaudeTrace with ReasoningSignals                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ STORE
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  TRACE STORAGE (claude_trace_schema.py)                  â”‚
â”‚                                                                          â”‚
â”‚  File: data/traces/traces.jsonl                                         â”‚
â”‚                                                                          â”‚
â”‚  Format (per line):                                                     â”‚
â”‚  {                                                                      â”‚
â”‚    "trace_id": "uuid",                                                  â”‚
â”‚    "user_prompt": "What's the difference...",                           â”‚
â”‚    "tool_calls": [                                                      â”‚
â”‚      {"tool": "Read", "reasoning": "...", "output": "..."},            â”‚
â”‚      {"tool": "Grep", "reasoning": "...", "output": "..."},            â”‚
â”‚      ...                                                                 â”‚
â”‚    ],                                                                    â”‚
â”‚    "reasoning_signals": {                                               â”‚
â”‚      "tool_sequence": ["Read", "Grep", "Bash", "Bash"],                â”‚
â”‚      "reasoning_steps": 5,                                              â”‚
â”‚      "exploration_depth": "thorough",                                   â”‚
â”‚      "multi_step_reasoning": true,                                      â”‚
â”‚      ...                                                                 â”‚
â”‚    },                                                                    â”‚
â”‚    "claude_response": "...",                                            â”‚
â”‚    ...                                                                   â”‚
â”‚  }                                                                      â”‚
â”‚                                                                          â”‚
â”‚  Goal: 500-1000 traces                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ BUILD DATASET
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       BEHAVIORAL CLONING DATASET (behavioral_cloning_builder.py)         â”‚
â”‚                                                                          â”‚
â”‚  Converts traces into SFT training samples:                             â”‚
â”‚                                                                          â”‚
â”‚  {                                                                      â”‚
â”‚    "prompt": "What's the difference...",                                â”‚
â”‚    "reasoning_chain": [                                                 â”‚
â”‚      "First, read schema to understand structure",                      â”‚
â”‚      "Then search for transformer references",                          â”‚
â”‚      ...                                                                 â”‚
â”‚    ],                                                                    â”‚
â”‚    "tool_sequence": [                                                   â”‚
â”‚      {"tool": "Read", "reasoning": "Understand schema"},                â”‚
â”‚      {"tool": "Grep", "reasoning": "Find references"},                  â”‚
â”‚      ...                                                                 â”‚
â”‚    ],                                                                    â”‚
â”‚    "response": "Claude's synthesized answer",                           â”‚
â”‚    "workflow_type": "exploratory",                                      â”‚
â”‚    "exploration_depth": "thorough"                                      â”‚
â”‚  }                                                                      â”‚
â”‚                                                                          â”‚
â”‚  File: data/datasets/bc_dataset.jsonl                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ TRAIN (Phase 1)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                SFT TRAINER (Coming in Week 2)                            â”‚
â”‚                                                                          â”‚
â”‚  Supervised Fine-Tuning on Claude's workflows:                          â”‚
â”‚                                                                          â”‚
â”‚  Base: unsloth/Meta-Llama-3.1-8B-Instruct                              â”‚
â”‚  Method: QLoRA (4-bit quantization)                                     â”‚
â”‚  LoRA config: rank=16, alpha=32                                         â”‚
â”‚  Training: 3 epochs, 4096 max length                                    â”‚
â”‚                                                                          â”‚
â”‚  Teaches LLaMA:                                                         â”‚
â”‚    âœ“ Basic tool usage patterns                                         â”‚
â”‚    âœ“ Step-by-step reasoning                                            â”‚
â”‚    âœ“ Workflow design fundamentals                                      â”‚
â”‚                                                                          â”‚
â”‚  Output: models/llama-claude-bc-v1.gguf                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ REFINE (Phase 2)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           BEHAVIORAL REWARD MODEL (Coming in Week 3)                     â”‚
â”‚                                                                          â”‚
â”‚  Scores LLaMA responses vs Claude traces:                               â”‚
â”‚                                                                          â”‚
â”‚  Reward Components:                                                     â”‚
â”‚    1. Constraint detection match (25%)                                  â”‚
â”‚       â†’ Did LLaMA catch same limitations?                               â”‚
â”‚                                                                          â”‚
â”‚    2. Tool use alignment (30%)                                          â”‚
â”‚       â†’ Same tools in similar order?                                    â”‚
â”‚       â†’ Levenshtein distance of sequences                               â”‚
â”‚                                                                          â”‚
â”‚    3. Self-correction behavior (15%)                                    â”‚
â”‚       â†’ Did LLaMA recover like Claude?                                  â”‚
â”‚                                                                          â”‚
â”‚    4. Outcome equivalence (20%)                                         â”‚
â”‚       â†’ Same final result?                                              â”‚
â”‚       â†’ Diff comparison for code edits                                  â”‚
â”‚                                                                          â”‚
â”‚    5. Reasoning depth (10%)                                             â”‚
â”‚       â†’ Explored enough before answering?                               â”‚
â”‚                                                                          â”‚
â”‚  Total reward: [-1.0, 1.0]                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ TRAIN (Phase 2)
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                PPO TRAINER (Coming in Weeks 3-6)                         â”‚
â”‚                                                                          â”‚
â”‚  Proximal Policy Optimization:                                          â”‚
â”‚                                                                          â”‚
â”‚  Training loop:                                                         â”‚
â”‚    1. LLaMA generates response for prompt                               â”‚
â”‚    2. Extract LLaMA's reasoning signals                                 â”‚
â”‚    3. Compare with Claude's trace (behavioral reward)                   â”‚
â”‚    4. PPO update (with KL penalty to stay close to Claude)              â”‚
â”‚                                                                          â”‚
â”‚  Iterative improvement:                                                 â”‚
â”‚    - Adversarial prompt mining (find divergent cases)                   â”‚
â”‚    - Prioritize retraining on gaps                                      â”‚
â”‚    - Checkpoint every 50 steps                                          â”‚
â”‚    - Quality gate: reward >0.80                                         â”‚
â”‚                                                                          â”‚
â”‚  Output: models/llama-claude-ppo-v{N}.gguf                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ DEPLOY
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DEPLOYMENT & TESTING (Week 7+)                              â”‚
â”‚                                                                          â”‚
â”‚  Export Pipeline:                                                       â”‚
â”‚    1. Merge LoRA adapters with base model                               â”‚
â”‚    2. Convert to GGUF format (f16)                                      â”‚
â”‚    3. Quantize to q4_k_m (balanced quality/size)                        â”‚
â”‚    4. Register with Ollama: cc-claude-agent:latest                      â”‚
â”‚                                                                          â”‚
â”‚  Testing:                                                                â”‚
â”‚    - Blind A/B test (50 samples)                                        â”‚
â”‚    - Users rate Claude vs LLaMA responses                               â”‚
â”‚    - Success: Indistinguishability >45%                                 â”‚
â”‚                                                                          â”‚
â”‚  Gradual Rollout:                                                       â”‚
â”‚    Week 1: 5% traffic â†’ LLaMA                                           â”‚
â”‚    Week 2: 20% traffic â†’ LLaMA                                          â”‚
â”‚    Week 3: 50% traffic â†’ LLaMA                                          â”‚
â”‚    Week 4+: 80% traffic â†’ LLaMA                                         â”‚
â”‚                                                                          â”‚
â”‚  Goal: Replace Claude entirely when indistinguishability >48%           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

```
User Question
    â†“
Claude Code (workflow design + execution)
    â†“
Capture System (claude_capture_hook.py)
    â†“
Reasoning Extraction (reasoning_extractor.py)
    â†“
Trace Storage (traces.jsonl)
    â†“
Dataset Builder (behavioral_cloning_builder.py)
    â†“
SFT Training (sft_trainer.py)
    â†“
Baseline Model (llama-claude-bc-v1.gguf)
    â†“
Behavioral Reward Model (behavioral_reward_model.py)
    â†“
PPO Training (ppo_trainer.py)
    â†“
Aligned Model (llama-claude-ppo-vN.gguf)
    â†“
GGUF Export & Ollama Deployment
    â†“
Local Claude-Quality Workflows ðŸŽ‰
```

## Component Interactions

### Phase 1: Capture (Week 1-2)
```
User â†’ ClaudeCapturer â†’ TraceStorage â†’ traces.jsonl
              â†‘
              â””â”€â”€â”€ ReasoningSignalExtractor
```

### Phase 2: Dataset (Week 2)
```
traces.jsonl â†’ BehavioralCloningDatasetBuilder â†’ bc_dataset.jsonl
```

### Phase 3: SFT (Week 2)
```
bc_dataset.jsonl â†’ SFTTrainer â†’ llama-claude-bc-v1.gguf
```

### Phase 4: PPO (Week 3-6)
```
llama-claude-bc-v1.gguf â†’ PPOTrainer â†â†’ BehavioralRewardModel
                               â†“
                    llama-claude-ppo-vN.gguf
                               â†“
                    AdversarialPromptMiner
                               â†“
                    (find gaps, retrain)
```

### Phase 5: Deploy (Week 7+)
```
llama-claude-ppo-vN.gguf â†’ GGUFExporter â†’ OllamaDeployer
                                              â†“
                                    cc-claude-agent:latest
                                              â†“
                                    IndistinguishabilityTest
                                              â†“
                                    (if >45%, deploy)
```

## Key Design Decisions

### 1. Why JSONL for Traces?
- Append-only (no file locking issues)
- Easy streaming (process one line at a time)
- Human-readable (can inspect with `tail -f`)
- Git-friendly (line-based diffs)

### 2. Why Separate Reasoning Extraction?
- Modular (can improve extraction without changing capture)
- Testable (can validate extraction on known traces)
- Extensible (can add new signal types)

### 3. Why Two-Phase Training (SFT + PPO)?
- SFT: Bootstrap basic patterns quickly
- PPO: Fine-tune for behavioral alignment
- Safer than pure RL (starts from supervised baseline)

### 4. Why Behavioral Rewards (not text similarity)?
- Text similarity doesn't capture workflow logic
- Same answer, different workflow = failure
- Behavioral alignment = same tools, same order, same depth

### 5. Why Adversarial Mining?
- Prevents overfitting to captured traces
- Finds edge cases proactively
- Ensures robustness

### 6. Why Gradual Rollout?
- Safety (can rollback if issues)
- A/B testing (measure real impact)
- User confidence (gradual transition)

---

## Success Criteria by Phase

### Phase 1: Capture
- âœ… 500+ diverse traces collected
- âœ… Traces cover: DB queries, file ops, complex reasoning, tool chains
- âœ… Reasoning signals extracted automatically
- âœ… Storage validated (can load all traces)

### Phase 2: Dataset
- âœ… Training samples built from traces
- âœ… Reasoning chains complete
- âœ… Tool sequences valid
- âœ… Dataset statistics look good (avg 4+ tools per sample)

### Phase 3: SFT
- âœ… Model converges (loss decreases)
- âœ… Can generate valid tool sequences
- âœ… Basic reasoning present
- âœ… No catastrophic failures (e.g., wrong file edits)

### Phase 4: PPO
- âœ… Behavioral reward >0.80 (on held-out set)
- âœ… Tool use alignment >85%
- âœ… Constraint detection >75%
- âœ… No regressions (new failure modes)

### Phase 5: Deploy
- âœ… Indistinguishability >45% (blind A/B)
- âœ… Zero production issues
- âœ… User satisfaction maintained
- âœ… **Goal: Remove Claude entirely** ðŸŽ‰

---

**This architecture enables local, Claude-quality workflows without API costs or external dependencies!**
